# 服务器测试操作手册（边牧级）

本手册提供从连接到服务器到执行数据集测试的完整流程。
请注意每条命令的执行环境bash/powershell

## 目录

1. [连接到服务器](#1-连接到服务器)
2. [环境检查](#2-环境检查)
3. [准备项目代码](#3-准备项目代码)
4. [构建 Docker 镜像](#4-构建-docker-镜像)
5. [启动容器](#5-启动容器)
6. [准备模型和数据](#6-准备模型和数据)
7. [执行测试](#7-执行测试)
8. [查看结果](#8-查看结果)
9. [常见问题](#9-常见问题)

---

## 1. 连接到服务器

### 1.1 SSH 连接

```bash
ssh username@server_ip
# 例如: ssh root@192.168.1.100
```

### 1.2 验证连接（可跳过）

```bash
# 检查当前目录
pwd

# 检查系统信息
uname -a

# 检查 GPU（如果已安装驱动）
nvidia-smi
```

---

## 2. 环境检查

### 2.1 检查 Docker

```bash
# 检查 Docker 版本
docker --version

# 检查 Docker 服务状态
systemctl status docker

# 如果未安装，安装 Docker
curl -fsSL https://get.docker.com | sh
```

### 2.2 检查 NVIDIA Container Toolkit

```bash
# 检查是否已安装
docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi

# 如果失败，安装 nvidia-container-toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### 2.3 检查 GPU

```bash
# 查看 GPU 信息
nvidia-smi

# 验证 Docker GPU 访问
docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi
```

---

## 3. 准备项目代码

### 3.1 方式一：Git 克隆（推荐）

```bash
# 进入工作目录
cd /opt  # 或其他目录

# 克隆项目
git clone <repository_url>
#项目地址：https://github.com/YANHAN-BLCU/NeuroLens.git

cd NeuroBreak-Reproduction
```

### 3.2 方式二：上传代码

```bash
# 在本地机器执行（使用 scp）
scp -r NeuroBreak-Reproduction username@server_ip:/opt/

# 或使用 rsync（支持增量同步）
rsync -av --progress NeuroBreak-Reproduction/ username@server_ip:/opt/NeuroBreak-Reproduction/
```

### 3.3 验证代码

```bash
cd /opt/NeuroBreak-Reproduction
ls -la
# 应看到: docker/, scripts/, engine/, requirements.txt 等
```

---

## 4. 构建 Docker 镜像（如果你不是服务器而是本地，这些命令也可以）

```bash
cd /opt/NeuroBreak-Reproduction

# 构建镜像（镜像名称: neurolens:v1.0）
docker build -t neurolens:v1.0 -f docker/Dockerfile .

# 验证镜像
docker images | grep neurolens
```

**预计时间**: 5-15 分钟（取决于网络速度）

---

## 5. 启动容器

### 5.1 准备环境变量

```bash
# 设置 ModelScope Token（如果使用 ModelScope）
export MODELSCOPE_TOKEN=your_token_here

#可用令牌：ms-d9625645-acb2-444f-b0df-6685dfc743b5

# 或创建 .env 文件（可选）
cat > /opt/NeuroBreak-Reproduction/.env <<EOF
MODELSCOPE_TOKEN=your_token_here
EOF
```

### 5.2 启动容器

```bash
cd /opt/NeuroBreak-Reproduction

docker run --gpus all -it \
  --name neurolens \
  -v $(pwd):/workspace \
  -v /opt/nb-cache:/workspace/.cache \
  -e MODELSCOPE_TOKEN=${MODELSCOPE_TOKEN} \
  neurolens:v1.0 \
  /bin/bash
```

**参数说明**:
- `--gpus all`: 启用所有 GPU
- `-it`: 交互式终端
- `--name`: 容器名称
- `-v $(pwd):/workspace`: 挂载项目目录
- `-v /opt/nb-cache:/workspace/.cache`: 挂载缓存目录
- `-e MODELSCOPE_TOKEN`: 传递 ModelScope Token

### 5.3 验证容器

```bash
# 在容器内执行
nvidia-smi
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
```

---

## 6. 准备模型和数据

### 6.1 检查模型路径

```bash
# 在容器内执行
cd /workspace

# 检查模型是否存在
ls -la /workspace/ms_models/LLM-Research/

# 应看到:
# - Meta-Llama-3-8B-Instruct/
# - Llama-Guard-3-8B/
```

### 6.2 如果模型不存在，下载模型

```bash
# 在容器内执行
export MODELSCOPE_TOKEN=your_token_here

# 下载模型
python scripts/download_models.py --all-8b --output /workspace/ms_models
```

**注意**: 模型较大（约 16GB），下载需要时间。

### 6.3 准备 SALAD 数据集

```bash
# 在容器内执行
cd /workspace

# 下载数据集（如果未下载）
python scripts/download_salad.py

# 验证数据集
ls -la /workspace/data/salad/raw/
# 应看到: base_set_train.jsonl, attack_enhanced_set_train.jsonl 等
```

---

## 7. 执行测试

### 7.1 快速测试（10 个样本）

#只测试一个也行，能跑出来就行

```bash
# 在容器内执行
cd /workspace

python scripts/evaluate_salad_pipeline.py \
  --data_dir /workspace/data/salad/raw \
  --output /workspace/logs/test_10.jsonl \
  --config base_set \
  --max_samples 10
```

### 7.2 完整测试（base_set，21,318 个样本）

```bash
# 在容器内执行
cd /workspace

# 创建输出目录
mkdir -p /workspace/logs

# 运行评估（建议使用 nohup 后台运行）
nohup python scripts/evaluate_salad_pipeline.py \
  --data_dir /workspace/data/salad/raw \
  --output /workspace/logs/base_set.jsonl \
  --config base_set \
  > /workspace/logs/base_set.log 2>&1 &

# 查看进度
tail -f /workspace/logs/base_set.log
```

### 7.3 其他配置测试

```bash
# attack_enhanced_set (5,000 样本)
python scripts/evaluate_salad_pipeline.py \
  --data_dir /workspace/data/salad/raw \
  --output /workspace/logs/attack_enhanced_set.jsonl \
  --config attack_enhanced_set

# defense_enhanced_set (200 样本)
python scripts/evaluate_salad_pipeline.py \
  --data_dir /workspace/data/salad/raw \
  --output /workspace/logs/defense_enhanced_set.jsonl \
  --config defense_enhanced_set

# mcq_set (3,840 样本)
python scripts/evaluate_salad_pipeline.py \
  --data_dir /workspace/data/salad/raw \
  --output /workspace/logs/mcq_set.jsonl \
  --config mcq_set
```

### 7.4 断点续传

```bash
# 从第 1000 个样本开始继续
python scripts/evaluate_salad_pipeline.py \
  --data_dir /workspace/data/salad/raw \
  --output /workspace/logs/base_set.jsonl \
  --config base_set \
  --start_from 1000
```

---

## 8. 查看结果

### 8.1 查看日志

```bash
# 在容器内执行
tail -f /workspace/logs/base_set.log

# 查看最后 100 行
tail -n 100 /workspace/logs/base_set.log
```

### 8.2 查看结果文件

```bash
# 在容器内执行
# 查看结果行数
wc -l /workspace/logs/base_set.jsonl

# 查看最后几条结果
tail -n 5 /workspace/logs/base_set.jsonl | python -m json.tool
```

### 8.3 分析结果（可选）（没必要）

```bash
# 在容器内执行
python scripts/analyze_salad_results.py \
  --input /workspace/logs/base_set.jsonl
```

### 8.4 从容器复制结果到宿主机

```bash
# 在宿主机执行（退出容器后）
docker cp neurolens:/workspace/logs/base_set.jsonl ./logs/
```

---

## 9. 常见问题（非常不常见，但是总会发生）

### 9.1 CUDA 不可用

**症状**: `torch.cuda.is_available()` 返回 `False`

**解决方案**:
```bash
# 1. 检查容器是否使用 --gpus all 启动
docker inspect neurolens | grep -i gpu

# 2. 检查 nvidia-smi 在容器内是否可用
docker exec neurolens nvidia-smi

# 3. 如果不可用，重新启动容器
docker stop neurolens
docker rm neurolens
# 然后使用 --gpus all 重新启动（见步骤 5.2）
```

### 9.2 显存不足（应该不用考虑）

**症状**: `CUDA out of memory`

**解决方案**:
- 模型已启用 4-bit 量化，如果仍不足，考虑：
  - 使用更小的 `max_tokens` 参数
  - 关闭其他占用 GPU 的程序
  - 使用 CPU 模式（会很慢）

### 9.3 模型路径找不到

**症状**: `FileNotFoundError: Model not found`

**解决方案**:
```bash
# 在容器内检查模型路径
python scripts/check_models.py

# 如果模型在宿主机，确保挂载正确
# 启动容器时添加: -v /host/path/to/models:/workspace/ms_models
```

### 9.4 数据集路径错误

**症状**: `Data directory not found`

**解决方案**:
```bash
# 检查数据集是否存在
ls -la /workspace/data/salad/raw/

# 如果不存在，下载数据集
python scripts/download_salad.py
```

### 9.5 容器退出后重新进入

```bash
# 查看容器状态
docker ps -a | grep neurolens

# 如果容器已停止，启动它
docker start neurolens

# 进入容器
docker exec -it neurolens /bin/bash
```

---

## 快速参考

### 常用命令

```bash
# 进入容器
docker exec -it neurolens /bin/bash

# 查看 GPU 使用情况
nvidia-smi

# 查看容器日志
docker logs neurolens

# 停止容器
docker stop neurolens

# 删除容器
docker rm neurolens

# 后台运行评估
nohup python scripts/evaluate_salad_pipeline.py ... > log.txt 2>&1 &

# 查看后台任务
jobs
# 或
ps aux | grep evaluate_salad
```

### 文件路径

- **项目代码**: `/workspace/`
- **模型路径**: `/workspace/ms_models/LLM-Research/`
- **数据集路径**: `/workspace/data/salad/raw/`
- **输出结果**: `/workspace/logs/`
- **缓存目录**: `/workspace/.cache/`

---

**完成以上步骤后，即可在服务器上执行数据集测试。如有问题，请参考常见问题部分或查看项目文档。**

