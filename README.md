# NeuroBreak-Reproduction

ä¸€ä¸ªé›†æˆäº† Llama æ¨ç†æ¨¡å‹å’Œ Llama Guard å®‰å…¨å®¡æ ¸çš„ AI åº”ç”¨ç³»ç»Ÿï¼Œæä¾›å®Œæ•´çš„ Web ç•Œé¢å’Œ API æœåŠ¡ã€‚

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- ğŸ¤– **æ™ºèƒ½æ¨ç†**ï¼šåŸºäº Meta Llama 3.2 æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆå’Œå¯¹è¯
- ğŸ›¡ï¸ **å®‰å…¨å®¡æ ¸**ï¼šé›†æˆ Llama Guard 3 è¿›è¡Œå†…å®¹å®‰å…¨æ£€æµ‹å’Œè¿‡æ»¤
- ğŸ¨ **ç°ä»£åŒ–å‰ç«¯**ï¼šåŸºäº React + TypeScript + Vite æ„å»ºçš„å“åº”å¼ Web ç•Œé¢
- ğŸš€ **é«˜æ€§èƒ½åç«¯**ï¼šFastAPI æä¾› RESTful API æœåŠ¡
- ğŸ³ **Docker æ”¯æŒ**ï¼šå®Œæ•´çš„å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ
- âš™ï¸ **çµæ´»é…ç½®**ï¼šæ”¯æŒè‡ªå®šä¹‰æ¨¡å‹å‚æ•°ã€å®¡æ ¸é˜ˆå€¼å’Œç±»åˆ«

## ğŸ—ï¸ æŠ€æœ¯æ ˆ

### åç«¯
- **æ¡†æ¶**ï¼šFastAPI 0.115.4
- **æ·±åº¦å­¦ä¹ **ï¼šPyTorch 2.6.0 + CUDA 11.8
- **æ¨¡å‹åº“**ï¼šTransformers 4.46.3
- **åŠ é€Ÿ**ï¼šAccelerate 1.1.1
- **æœåŠ¡å™¨**ï¼šUvicorn 0.32.0

### å‰ç«¯
- **æ¡†æ¶**ï¼šReact 19.2.0 + TypeScript 5.9.3
- **æ„å»ºå·¥å…·**ï¼šVite 7.2.4
- **æ ·å¼**ï¼šTailwind CSS 3.4.14
- **çŠ¶æ€ç®¡ç†**ï¼šZustand 5.0.8
- **æ•°æ®è·å–**ï¼šTanStack Query 5.90.10
- **å›¾è¡¨**ï¼šRecharts 3.5.0

### éƒ¨ç½²
- **å®¹å™¨åŒ–**ï¼šDocker + NVIDIA CUDA 11.8
- **æ¨¡å‹ç®¡ç†**ï¼šHuggingFace Transformers

## ğŸ“‹ å‰ææ¡ä»¶

- Python 3.9+
- Node.js 18+ (ç”¨äºå‰ç«¯å¼€å‘)
- CUDA 11.8+ (æ¨èï¼Œç”¨äº GPU åŠ é€Ÿ)
- Docker (å¯é€‰ï¼Œç”¨äºå®¹å™¨åŒ–éƒ¨ç½²)
- HuggingFace è´¦å·å’Œè®¿é—®ä»¤ç‰Œï¼ˆéœ€è¦ç”³è¯· Llama æ¨¡å‹è®¿é—®æƒé™ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†ä»“åº“

```bash
git clone https://github.com/YANHAN-BLCU/NeuroBreak-Reproduction-.git
cd NeuroBreak-Reproduction
```

### 2. å®‰è£…åç«¯ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆæˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼‰ï¼š

```bash
# HuggingFace Token
HF_TOKEN=your_huggingface_token_here

# æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ HuggingFace ç¼“å­˜ï¼‰
MODEL_CACHE_DIR=/path/to/models
```

### 4. ä¸‹è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨æä¾›çš„è„šæœ¬ä¸‹è½½æ¨¡å‹ï¼š

```bash
python scripts/download_models.py
```

### 5. å¯åŠ¨åç«¯æœåŠ¡

```bash
# æ–¹æ³•1: ä½¿ç”¨å¯åŠ¨è„šæœ¬
python scripts/start_server.py

# æ–¹æ³•2: ä½¿ç”¨ uvicorn
uvicorn engine.server:app --host 0.0.0.0 --port 8000 --reload
```

åç«¯å°†åœ¨ `http://localhost:8000` å¯åŠ¨ã€‚

### 6. å¯åŠ¨å‰ç«¯ï¼ˆå¼€å‘æ¨¡å¼ï¼‰

```bash
cd frontend
npm install
npm run dev
```

å‰ç«¯å°†åœ¨ `http://localhost:5173` å¯åŠ¨ã€‚

### 7. æ„å»ºå‰ç«¯ï¼ˆç”Ÿäº§æ¨¡å¼ï¼‰

```bash
cd frontend
npm run build
```

æ„å»ºäº§ç‰©å°†è¾“å‡ºåˆ° `frontend/dist/` ç›®å½•ã€‚

## ğŸ³ Docker éƒ¨ç½²

### æ„å»ºé•œåƒ

```bash
docker build -t neurobreak:latest -f docker/Dockerfile .
```

### è¿è¡Œå®¹å™¨

```bash
docker run -it --gpus all \
  -p 8000:8000 \
  -v /path/to/models:/cache \
  -e HF_TOKEN=your_token \
  neurobreak:latest
```

è¯¦ç»†éƒ¨ç½²æŒ‡å—è¯·å‚è€ƒ [DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
NeuroBreak-Reproduction/
â”œâ”€â”€ engine/                 # åç«¯æœåŠ¡
â”‚   â”œâ”€â”€ server.py          # FastAPI åº”ç”¨ä¸»æ–‡ä»¶
â”‚   â”œâ”€â”€ models.py          # æ¨¡å‹ç®¡ç†æ¨¡å—
â”‚   â””â”€â”€ README.md          # åç«¯æ–‡æ¡£
â”œâ”€â”€ frontend/              # å‰ç«¯åº”ç”¨
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ lib/           # API å®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ store/         # çŠ¶æ€ç®¡ç†
â”‚   â”‚   â””â”€â”€ types/         # TypeScript ç±»å‹å®šä¹‰
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docs/                  # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ QUICK_START.md     # å¿«é€Ÿå¯åŠ¨æŒ‡å—
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md # éƒ¨ç½²æŒ‡å—
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/               # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ start_server.py    # æœåŠ¡å™¨å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ download_models.py # æ¨¡å‹ä¸‹è½½è„šæœ¬
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docker/                # Docker é…ç½®
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt       # Python ä¾èµ–
â””â”€â”€ README.md             # æœ¬æ–‡ä»¶
```

## ğŸ”Œ API æ–‡æ¡£

### å¥åº·æ£€æŸ¥

```bash
GET /health
```

### æ¨ç† + å®¡æ ¸è”åˆæµç¨‹

```bash
POST /api/pipeline/run
Content-Type: application/json

{
  "prompt": "ç”¨æˆ·è¾“å…¥æ–‡æœ¬",
  "inferenceConfig": {
    "modelId": "meta-llama/Llama-3.2-3B-Instruct",
    "temperature": 0.7,
    "topP": 0.9,
    "maxTokens": 512,
    "stream": false
  },
  "guardConfig": {
    "modelId": "meta-llama/Llama-Guard-3-1B",
    "threshold": 0.5,
    "autoBlock": false,
    "categories": ["violence", "politics"]
  }
}
```

### ç‹¬ç«‹å®‰å…¨å®¡æ ¸

```bash
POST /api/moderate
Content-Type: application/json

{
  "text": "å¾…å®¡æ ¸æ–‡æœ¬",
  "threshold": 0.5,
  "categories": ["violence", "politics"]
}
```

æ›´å¤š API è¯¦æƒ…è¯·å‚è€ƒ [engine/README.md](engine/README.md)ã€‚

## ğŸ“š æ–‡æ¡£

- [å¿«é€Ÿå¯åŠ¨æŒ‡å—](docs/QUICK_START.md) - å¿«é€Ÿä¸Šæ‰‹æŒ‡å—
- [éƒ¨ç½²æŒ‡å—](docs/DEPLOYMENT_GUIDE.md) - è¯¦ç»†éƒ¨ç½²è¯´æ˜
- [æ¨¡å‹é€‚é…æ€»ç»“](docs/MODEL_ADAPTATION_SUMMARY.md) - æ¨¡å‹é…ç½®è¯´æ˜
- [Docker æ¨¡å‹æŒ‚è½½](docs/DOCKER_MODEL_MOUNT.md) - Docker æ¨¡å‹ç®¡ç†

## ğŸ§ª æµ‹è¯•

è¿è¡Œ IO æµ‹è¯•ï¼š

```bash
python scripts/run_io_tests.py
```

## ğŸ”§ å¼€å‘

### ä»£ç æ ¼å¼åŒ–

```bash
# Python
black .
isort .
ruff check .

# TypeScript/React
cd frontend
npm run lint
```

### æ£€æŸ¥æ¨¡å‹

```bash
python scripts/check_models.py
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹è®¿é—®æƒé™**ï¼šéœ€è¦ç”³è¯· Meta Llama å’Œ Llama Guard æ¨¡å‹çš„è®¿é—®æƒé™
2. **GPU æ¨è**ï¼šè™½ç„¶å¯ä»¥åœ¨ CPU ä¸Šè¿è¡Œï¼Œä½† GPU ä¼šæ˜¾è‘—æå‡æ€§èƒ½
3. **é¦–æ¬¡åŠ è½½**ï¼šæ¨¡å‹é¦–æ¬¡åŠ è½½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡
4. **å†…å­˜è¦æ±‚**ï¼šå»ºè®®è‡³å°‘ 16GB RAMï¼Œä½¿ç”¨ GPU æ—¶å»ºè®® 8GB+ VRAM
5. **ç½‘ç»œè¦æ±‚**ï¼šé¦–æ¬¡è¿è¡Œéœ€è¦ä» HuggingFace ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 10GB+ï¼‰

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ã€‚ä½¿ç”¨ Meta Llama æ¨¡å‹éœ€è¦éµå®ˆ [Llama ä½¿ç”¨æ¡æ¬¾](https://ai.meta.com/llama/use-policy/)ã€‚

## ğŸ™ è‡´è°¢

- [Meta Llama](https://ai.meta.com/llama/) - æä¾›å¼ºå¤§çš„è¯­è¨€æ¨¡å‹
- [HuggingFace](https://huggingface.co/) - æ¨¡å‹æ‰˜ç®¡å’Œ Transformers åº“
- [FastAPI](https://fastapi.tiangolo.com/) - ç°ä»£ Python Web æ¡†æ¶
- [React](https://react.dev/) - å‰ç«¯ UI æ¡†æ¶

## ğŸ“® è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ GitHub Issues è”ç³»ã€‚

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Starï¼**

