# NeuroLens

ä¸€ä¸ªé›†æˆäº† Llama æ¨ç†æ¨¡å‹å’Œ Llama Guard å®‰å…¨å®¡æ ¸çš„ AI åº”ç”¨ç³»ç»Ÿï¼Œæä¾›å®Œæ•´çš„ Web ç•Œé¢å’Œ API æœåŠ¡ã€‚

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- ğŸ¤– **æ™ºèƒ½æ¨ç†**ï¼šåŸºäº Meta Llama 3 8B æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆå’Œå¯¹è¯
- ğŸ›¡ï¸ **å®‰å…¨å®¡æ ¸**ï¼šé›†æˆ Llama Guard 3 è¿›è¡Œå†…å®¹å®‰å…¨æ£€æµ‹å’Œè¿‡æ»¤
- ğŸ§ª **SALAD è¯„ä¼°**ï¼šæ”¯æŒ SALAD-Bench æ•°æ®é›†è¯„ä¼°ï¼Œæµ‹è¯•æ¨¡å‹å®‰å…¨é˜²æŠ¤èƒ½åŠ›
- ğŸ¨ **ç°ä»£åŒ–å‰ç«¯**ï¼šåŸºäº React + TypeScript + Vite æ„å»ºçš„å“åº”å¼ Web ç•Œé¢
- ğŸš€ **é«˜æ€§èƒ½åç«¯**ï¼šFastAPI æä¾› RESTful API æœåŠ¡
- ğŸ³ **Docker æ”¯æŒ**ï¼šå®Œæ•´çš„å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ
- âš™ï¸ **çµæ´»é…ç½®**ï¼šæ”¯æŒè‡ªå®šä¹‰æ¨¡å‹å‚æ•°ã€å®¡æ ¸é˜ˆå€¼å’Œç±»åˆ«

## ğŸ—ï¸ æŠ€æœ¯æ ˆ

### åç«¯
- **æ¡†æ¶**ï¼šFastAPI 0.115.4
- **æ·±åº¦å­¦ä¹ **ï¼šPyTorch 2.6.0 + CUDA 11.8
- **æ¨¡å‹åº“**ï¼šTransformers 4.46.3
- **åŠ é€Ÿ**ï¼šAccelerate 1.1.1
- **æœåŠ¡å™¨**ï¼šUvicorn 0.32.0

### å‰ç«¯
- **æ¡†æ¶**ï¼šReact 19.2.0 + TypeScript 5.9.3
- **æ„å»ºå·¥å…·**ï¼šVite 7.2.4
- **æ ·å¼**ï¼šTailwind CSS 3.4.14
- **çŠ¶æ€ç®¡ç†**ï¼šZustand 5.0.8
- **æ•°æ®è·å–**ï¼šTanStack Query 5.90.10
- **å›¾è¡¨**ï¼šRecharts 3.5.0

### éƒ¨ç½²
- **å®¹å™¨åŒ–**ï¼šDocker + NVIDIA CUDA 12.4
- **æ¨¡å‹ç®¡ç†**ï¼šModelScopeï¼ˆæ¨èï¼Œä¸­å›½å¤§é™†è®¿é—®æ›´å¿«ï¼‰æˆ– HuggingFace Transformers

## ğŸ“‹ å‰ææ¡ä»¶

- Python 3.9+
- Node.js 18+ (ç”¨äºå‰ç«¯å¼€å‘)
- CUDA 12.4+ (æ¨èï¼Œç”¨äº GPU åŠ é€Ÿï¼Œ8B æ¨¡å‹éœ€è¦)
- Docker (å¯é€‰ï¼Œç”¨äºå®¹å™¨åŒ–éƒ¨ç½²)
- ModelScope è´¦å·ï¼ˆæ¨èï¼Œä¸­å›½å¤§é™†è®¿é—®æ›´å¿«ï¼‰æˆ– HuggingFace è´¦å·ï¼Œå·²ç”³è¯·æ¨¡å‹è®¿é—®æƒé™
  - ModelScope: `LLM-Research/Meta-Llama-3-8B-Instruct` ä¸ `LLM-Research/Llama-Guard-3-8B`
  - HuggingFace: `meta-llama/Meta-Llama-3-8B-Instruct` ä¸ `meta-llama/Llama-Guard-3-8B`

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†ä»“åº“

```bash
git clone https://github.com/YANHAN-BLCU/NeuroBreak-Reproduction-.git
cd NeuroBreak-Reproduction
```

### 2. å®‰è£…åç«¯ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆæˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼‰ï¼š

```bash
# ModelScope Tokenï¼ˆæ¨èï¼Œä¸­å›½å¤§é™†è®¿é—®æ›´å¿«ï¼‰
MODELSCOPE_TOKEN=your_modelscope_token_here

# æˆ–è€…ä½¿ç”¨ HuggingFace Token
# HF_TOKEN=your_huggingface_token_here

# æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ ModelScope/HuggingFace ç¼“å­˜ï¼‰
MODEL_CACHE_DIR=/path/to/models
```

### 4. ä¸‹è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨æä¾›çš„è„šæœ¬ä¸‹è½½æ¨¡å‹ï¼š

```bash
# ä¸‹è½½é»˜è®¤çš„ 8B æ¨¡å‹ï¼ˆä½¿ç”¨ ModelScopeï¼‰
python scripts/download_models.py --all-8b

# è®¾ç½® ModelScope tokenï¼ˆå¦‚æœéœ€è¦ï¼‰
export MODELSCOPE_TOKEN=your_token
python scripts/download_models.py --all-8b
```

### 5. å¯åŠ¨åç«¯æœåŠ¡

```bash
# æ–¹æ³•1: ä½¿ç”¨å¯åŠ¨è„šæœ¬
python scripts/start_server.py

# æ–¹æ³•2: ä½¿ç”¨ uvicorn
uvicorn engine.server:app --host 0.0.0.0 --port 8000 --reload
```

åç«¯å°†åœ¨ `http://localhost:8000` å¯åŠ¨ã€‚

### 6. å¯åŠ¨å‰ç«¯ï¼ˆå¼€å‘æ¨¡å¼ï¼‰

```bash
cd frontend
npm install
npm run dev
```

å‰ç«¯å°†åœ¨ `http://localhost:5173` å¯åŠ¨ã€‚

### 7. æ„å»ºå‰ç«¯ï¼ˆç”Ÿäº§æ¨¡å¼ï¼‰

```bash
cd frontend
npm run build
```

æ„å»ºäº§ç‰©å°†è¾“å‡ºåˆ° `frontend/dist/` ç›®å½•ã€‚

## ğŸ³ Docker éƒ¨ç½²

### æ„å»ºé•œåƒ

```bash
docker build -t neurobreak:latest -f docker/Dockerfile .
```

### è¿è¡Œå®¹å™¨

```bash
docker run -it --gpus all \
  -p 8000:8000 \
  -v /path/to/models:/cache \
  -v /path/to/workspace/hf_models:/workspace/hf_models \
  -e MODELSCOPE_TOKEN=your_token \
  neurobreak:latest
```

**æ³¨æ„**ï¼š
- æ¨¡å‹è·¯å¾„å·²æ›´æ–°ä¸º `/workspace/ms_models`ï¼Œè¯·ç¡®ä¿æ­£ç¡®æŒ‚è½½æ¨¡å‹ç›®å½•
- æ¨èä½¿ç”¨ ModelScope tokenï¼ˆ`MODELSCOPE_TOKEN`ï¼‰ï¼Œä¸­å›½å¤§é™†è®¿é—®é€Ÿåº¦æ›´å¿«
- å¦‚æœä½¿ç”¨ HuggingFaceï¼Œå¯è®¾ç½® `HF_TOKEN` ç¯å¢ƒå˜é‡

è¯¦ç»†éƒ¨ç½²æŒ‡å—è¯·å‚è€ƒ [DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
NeuroBreak-Reproduction/
â”œâ”€â”€ engine/                 # åç«¯æœåŠ¡
â”‚   â”œâ”€â”€ server.py          # FastAPI åº”ç”¨ä¸»æ–‡ä»¶
â”‚   â”œâ”€â”€ models.py          # æ¨¡å‹ç®¡ç†æ¨¡å—
â”‚   â””â”€â”€ README.md          # åç«¯æ–‡æ¡£
â”œâ”€â”€ frontend/              # å‰ç«¯åº”ç”¨
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ lib/           # API å®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ store/         # çŠ¶æ€ç®¡ç†
â”‚   â”‚   â””â”€â”€ types/         # TypeScript ç±»å‹å®šä¹‰
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docs/                  # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ QUICK_START.md     # å¿«é€Ÿå¯åŠ¨æŒ‡å—
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md # éƒ¨ç½²æŒ‡å—
â”‚   â”œâ”€â”€ SALAD_EVALUATION_GUIDE.md # SALAD è¯„ä¼°æŒ‡å—
â”‚   â”œâ”€â”€ SALAD_EVALUATION_ANALYSIS.md # SALAD è¯„ä¼°åˆ†ææŠ¥å‘Š
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/               # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ start_server.py    # æœåŠ¡å™¨å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ download_models.py # æ¨¡å‹ä¸‹è½½è„šæœ¬
â”‚   â”œâ”€â”€ evaluate_salad_pipeline.py # SALAD è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ analyze_salad_results.py # SALAD ç»“æœåˆ†æè„šæœ¬
â”‚   â””â”€â”€ ...
â”œâ”€â”€ hf_models/            # æ¨¡å‹æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ Meta-Llama-3-8B-Instruct/
â”‚   â””â”€â”€ Llama-Guard-3-8B/
â”œâ”€â”€ docker/                # Docker é…ç½®
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt       # Python ä¾èµ–
â””â”€â”€ README.md             # æœ¬æ–‡ä»¶
```

## ğŸ”Œ API æ–‡æ¡£

### å¥åº·æ£€æŸ¥

```bash
GET /health
```

### æ¨ç† + å®¡æ ¸è”åˆæµç¨‹

```bash
POST /api/pipeline/run
Content-Type: application/json

{
  "prompt": "ç”¨æˆ·è¾“å…¥æ–‡æœ¬",
  "inferenceConfig": {
    "modelId": "LLM-Research/Meta-Llama-3-8B-Instruct",
    "temperature": 0.7,
    "topP": 0.9,
    "maxTokens": 512,
    "stream": false
  },
  "guardConfig": {
    "modelId": "LLM-Research/Llama-Guard-3-8B",
    "threshold": 0.7,
    "autoBlock": false,
    "categories": ["violence", "politics"]
  }
}
```

### ç‹¬ç«‹å®‰å…¨å®¡æ ¸

```bash
POST /api/moderate
Content-Type: application/json

{
  "text": "å¾…å®¡æ ¸æ–‡æœ¬",
  "threshold": 0.7,
  "categories": ["violence", "politics"]
}
```

æ›´å¤š API è¯¦æƒ…è¯·å‚è€ƒ [engine/README.md](engine/README.md)ã€‚

## ğŸ“š æ–‡æ¡£

- [å¿«é€Ÿå¯åŠ¨æŒ‡å—](docs/QUICK_START.md) - å¿«é€Ÿä¸Šæ‰‹æŒ‡å—
- [éƒ¨ç½²æŒ‡å—](docs/DEPLOYMENT_GUIDE.md) - è¯¦ç»†éƒ¨ç½²è¯´æ˜
- [æ¨¡å‹é€‚é…æ€»ç»“](docs/MODEL_ADAPTATION_SUMMARY.md) - æ¨¡å‹é…ç½®è¯´æ˜
- [Docker æ¨¡å‹æŒ‚è½½](docs/DOCKER_MODEL_MOUNT.md) - Docker æ¨¡å‹ç®¡ç†
- [SALAD è¯„ä¼°æŒ‡å—](docs/SALAD_EVALUATION_GUIDE.md) - SALAD-Bench æ•°æ®é›†è¯„ä¼°æŒ‡å—
- [SALAD è¯„ä¼°åˆ†æ](docs/SALAD_EVALUATION_ANALYSIS.md) - SALAD è¯„ä¼°ç»“æœåˆ†ææŠ¥å‘Š

## ğŸ§ª æµ‹è¯•

### IO æµ‹è¯•

è¿è¡Œ IO æµ‹è¯•ï¼š

```bash
python scripts/run_io_tests.py
```

### SALAD-Bench è¯„ä¼°

è¿è¡Œ SALAD-Bench æ•°æ®é›†è¯„ä¼°ï¼ˆéœ€è¦å…ˆä¸‹è½½æ•°æ®é›†ï¼‰ï¼š

```bash
# åœ¨ Docker å®¹å™¨å†…è¿è¡Œ
docker exec -it neurobreak-container /bin/bash
cd /workspace
python scripts/evaluate_salad_pipeline.py \
    --data_dir /workspace/data/salad/raw \
    --output /workspace/logs/salad_evaluation.jsonl \
    --config base_set \
    --max_samples 100
```

æˆ–ä½¿ç”¨ PowerShell è„šæœ¬ï¼ˆWindowsï¼‰ï¼š

```powershell
.\scripts\run_salad_evaluation.ps1 -Config base_set -MaxSamples 100
```

**æ”¯æŒçš„é…ç½®**ï¼š
- `base_set`: åŸºç¡€æ•°æ®é›†ï¼ˆ21,318 æ ·æœ¬ï¼‰
- `attack_enhanced_set`: æ”»å‡»å¢å¼ºé›†ï¼ˆ5,000 æ ·æœ¬ï¼‰
- `defense_enhanced_set`: é˜²å¾¡å¢å¼ºé›†ï¼ˆ200 æ ·æœ¬ï¼‰
- `mcq_set`: å¤šé€‰é¢˜é›†ï¼ˆ3,840 æ ·æœ¬ï¼‰

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [SALAD è¯„ä¼°æŒ‡å—](docs/SALAD_EVALUATION_GUIDE.md)ã€‚

### åˆ†æè¯„ä¼°ç»“æœ

åˆ†æ SALAD è¯„ä¼°ç»“æœï¼š

```bash
python scripts/analyze_salad_results.py
```

## ğŸ”§ å¼€å‘

### ä»£ç æ ¼å¼åŒ–

```bash
# Python
black .
isort .
ruff check .

# TypeScript/React
cd frontend
npm run lint
```

### æ£€æŸ¥æ¨¡å‹

```bash
python scripts/check_models.py
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹è®¿é—®æƒé™**ï¼šéœ€è¦ç”³è¯· Meta Llama å’Œ Llama Guard æ¨¡å‹çš„è®¿é—®æƒé™
   - ModelScopeï¼ˆæ¨èï¼‰ï¼šè®¿é—® https://modelscope.cn ç”³è¯·æ¨¡å‹æƒé™
   - HuggingFaceï¼šè®¿é—® https://huggingface.co ç”³è¯·æ¨¡å‹æƒé™
2. **æ¨¡å‹è·¯å¾„**ï¼šæ¨¡å‹é»˜è®¤è·¯å¾„ä¸º `/workspace/ms_models`ï¼ˆå®¹å™¨å†…ï¼‰æˆ– `hf_models/`ï¼ˆæœ¬åœ°ï¼‰
3. **æ¨¡å‹ä¸‹è½½**ï¼šæ¨èä½¿ç”¨ ModelScope ä¸‹è½½æ¨¡å‹ï¼Œä¸­å›½å¤§é™†è®¿é—®é€Ÿåº¦æ›´å¿«
4. **GPU æ¨è**ï¼š8B æ¨¡å‹éœ€è¦ GPU æ”¯æŒï¼Œå»ºè®®ä½¿ç”¨ NVIDIA GPUï¼ˆ16GB+ VRAMï¼‰
5. **é¦–æ¬¡åŠ è½½**ï¼š8B æ¨¡å‹é¦–æ¬¡åŠ è½½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡
6. **å†…å­˜è¦æ±‚**ï¼šå»ºè®®è‡³å°‘ 32GB RAMï¼Œä½¿ç”¨ GPU æ—¶å»ºè®® 16GB+ VRAMï¼ˆ8B æ¨¡å‹ï¼‰
7. **ç½‘ç»œè¦æ±‚**ï¼šé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 16GB+ï¼‰ï¼Œä½¿ç”¨ ModelScope å¯åŠ é€Ÿä¸‹è½½
8. **SALAD è¯„ä¼°**ï¼šè¿è¡Œ SALAD è¯„ä¼°å‰éœ€è¦å…ˆä¸‹è½½ SALAD-Bench æ•°æ®é›†

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ã€‚ä½¿ç”¨ Meta Llama æ¨¡å‹éœ€è¦éµå®ˆ [Llama ä½¿ç”¨æ¡æ¬¾](https://ai.meta.com/llama/use-policy/)ã€‚

## ğŸ™ è‡´è°¢

- [Meta Llama](https://ai.meta.com/llama/) - æä¾›å¼ºå¤§çš„è¯­è¨€æ¨¡å‹
- [ModelScope](https://modelscope.cn/) - æ¨¡å‹æ‰˜ç®¡å¹³å°ï¼ˆä¸­å›½å¤§é™†æ¨èï¼‰
- [HuggingFace](https://huggingface.co/) - æ¨¡å‹æ‰˜ç®¡å’Œ Transformers åº“
- [FastAPI](https://fastapi.tiangolo.com/) - ç°ä»£ Python Web æ¡†æ¶
- [React](https://react.dev/) - å‰ç«¯ UI æ¡†æ¶

## ğŸ“® è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ GitHub Issues è”ç³»ã€‚

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Starï¼**

