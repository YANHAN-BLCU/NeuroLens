## 复现目标概述

- **论文**：NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models（IEEE TVCG 2025）
- **核心贡献**：构建“解释引擎 + 可视化界面”的多粒度安全诊断系统，支持对 LLM 在越狱攻击下的层级语义演化、安全神经元定位与定向微调。
- **复现目标**：在可获得的硬件资源与公开数据基础上，最大程度还原系统方法、交互流程与主要实验结果（案例分析 + 定量评估）。
- **输出物**：完整代码仓库、实验脚本、可视化界面、复现实验报告、关键截图/视频、模型权重与日志。

---

## 总体路线与时间规划

| 阶段 | 目标 | 关键输出 | 预估时间 |
| ---- | ---- | -------- | -------- |
| 0. 准备 | 团队分工、硬件与数据确认 | 复现资源清单 | 1 周 |
| 1. 环境搭建 | 统一开发/训练环境、获取论文依赖 | Docker/conda 配置、工具链 | 1 周 |
| 2. 数据与评测基线 | 落地 SALAD-Bench + 安全分类器 + 通用任务评测 | 评测脚本、ASR/utility 基线 | 2 周 |
| 3. 解释引擎实现 | 完成评估、探针、神经元分析、微调模块 | Python 模块化实现、单元测试 | 4 周 |
| 4. 可视化界面 | 前后端联调，实现论文 6 个视图与交互 | Demo 应用、关键交互回放 | 3 周 |
| 5. 实验复现 | 复现实验 7.1/7.2/7.3，生成表格图形 | 复现报告、结果对比 | 3 周 |
| 6. 文档与开源 | 清理代码、撰写说明、录制演示 | README、使用指南、演示视频 | 1 周 |

> 注：若硬件资源有限，可先以中等规模模型（如 Llama-2-7B-chat）跑通流程，待验证后再切换论文配置。

---

## 阶段 0：准备工作

- **团队角色**：算法/模型（负责解释引擎与实验）、前端可视化、数据处理、基础设施/DevOps。
- **硬件资源**：理想情况 4×A100 80GB；最少保证 >=40GB GPU 及充足存储（原始数据 ~20GB + 中间特征 ~300GB）。
- **软件栈**：
  - Python 3.10+，PyTorch ≥ 2.1，HuggingFace Transformers、Accelerate。
  - 科学计算：NumPy、Pandas、scikit-learn、SciPy。
  - 可视化后端：Flask/FastAPI；前端：React/Vue + ECharts/Plotly/D3。
  - 训练/评测辅助：Weights & Biases（或自建日志）、Prefect/Airflow（如需流程编排）。
- **代码仓库规划**：
  ```
  NeuroBreak-Reproduction/
  ├── configs/            # 模型、训练、可视化配置
  ├── data/               # 数据读取脚本与缓存
  ├── engine/             # 解释引擎
  │   ├── assessment/
  │   ├── probing/
  │   ├── neurons/
  │   └── fine_tuning/
  ├── frontend/
  ├── notebooks/          # 快速验证、可视化草稿
  ├── scripts/            # 端到端运行脚本
  ├── tests/
  └── docs/
  ```
- **规范**：PEP8、Git Flow、统一日志格式（JSON Lines），代码评审与自动化测试。

---

## 阶段 1：环境搭建

1. **依赖安装**：编写 `environment.yml` / Dockerfile，包含：
   - `pytorch`, `transformers`, `accelerate`, `datasets`, `sentencepiece`
   - `scikit-learn`, `numpy`, `scipy`, `pandas`
   - `flask`, `fastapi`, `uvicorn`, `gunicorn`
   - `plotly`, `dash`, 或 `echarts-for-react`
   - `wandb`、`hydra-core`（配置管理可选）
2. **大模型下载**：
   - meta-llama/Llama-3.2-3B（如无官方渠道，可替换为兼容模型并记录差异）
   - 安全分类器：Llama-Guard-3-1B 或等效替代
3. **基础设施**：
   - 配置 HuggingFace Token、模型缓存路径
   - 制定数据缓存策略（层级隐藏态可采用 HDF5 / Zarr 存储）
4. **CI/CD**：
   - 设置单元测试框架（pytest）
   - 配置 lint（ruff/flake8）与格式化（black/isort）

交付物：环境安装文档、Docker 镜像、CI 工作流配置。

---

## 阶段 2：数据与评测基线

### 2.1 SALAD-Bench 数据管线
- 下载并解析五类越狱攻击（人工、TAP、AutoDan、GPT-Fuzzer、GCG）。
- 构建统一 schema：`{id, attack_type, prompt, base_prompt, template, reference_label}`。
- 划分集合：分析集（≥100/类）、评估集（≥100/类）、微调集（成功越狱样本）。
- 实现缓存与增量更新机制（HuggingFace Datasets arrow 文件或自定义缓存）。

### 2.2 安全性评估
- 对接 Llama-Guard-3-1B（或其他安全分类器）接口，输出置信度/标签。
- 编写批量推理脚本：推送越狱 prompt，收集模型回复、越狱成功标签（ASR）。
- 记录指标：总体 ASR、各攻击 ASR、响应时长、平均 tokens。
- 保存原始响应与评分结果，用于后续联动。

### 2.3 通用任务评测
- 依据 Sun et al. 协议选取：Commonsense（CSQA/PIQA）、科学问答、阅读理解（RACE）。
- 构建小规模验证集，编写评测脚本输出准确率/得分。
- 架构选择：使用 Prompt-based 统一接口，支持模型切换。

### 2.4 基线报告
- 生成首版评测报告（Markdown + 图表），作为后续迭代对照。

---

## 阶段 3：解释引擎实现

### 3.1 模块一：Jailbreak Assessment（R1）
- **输入**：模型预测结果、分类器判定、通用任务得分。
- **输出**：指标 JSON（每类攻击 ASR、总体 ASR、效用指标）。
- **接口**：`engine/assessment/evaluate.py`，支持命令行与 API 调用。
- **测试**：构造伪造数据验证指标计算正确性。

### 3.2 模块二：Jailbreak Probing（R2）
- **数据采集**：
  - 对分析集样本执行模型前向，保存每层最后 token 的隐藏态（可使用 hooks）。
  - 建议批量化 + 半精度存储（float16）压缩。
- **探针训练**：
  - 每层训练 softmax/LogReg 探针，使用 scikit-learn 或 PyTorch 轻量模型。
  - 训练/验证 9:1，记录准确率、ROC-AUC、PR-AUC。
  - 自动过滤精度 <75% 的浅层探针（可标注“无效层”）。
- **毒性向量**：
  - 保存每层探针权重 `w_toxic` 与偏置，归一化后写入二进制文件。
  - 设计数据格式：`probes/{model_id}/{layer}.npz`。
- **语义演化统计**：
  - 计算成功/失败样本在决策边界上的投影距离，生成层级统计（均值、中值、IQR）。
- **验证**：在 notebooks 中绘制层级探针精度曲线，确认与论文描述一致（15 层后 >90%）。

### 3.3 模块三：安全神经元定位（R3）
- **SNIP 评分**：
  - 采用 Wei et al. 方法，对 benign 参考集前向，计算每个神经元对损失的贡献。
  - 参数：安全阈值 `q`（例如 0.5%）。输出安全候选集。
- **效用过滤**：
  - 在 Alpaca/通用任务上重算 SNIP 分数，选取前 `p`（例如 0.1%）效用神经元。
  - `D(p,q) = S(q) \ U(p)` 得到专属安全神经元。
- **数据结构**：`neurons/safety_set.json`，记录层号、索引、分数、是否被过滤。
- **单元测试**：构造小型前馈网络验证 SNIP 实现正确。

### 3.4 模块四：神经元功能分析（R4/R5）
- **参数对齐 \(S_i^k\)**：
  - 计算每层 W_down 行向量与 `w_toxic` 的余弦相似度，判定固有方向。
- **激活投影 \(A_i^k\)**：
  - 收集指定样本集合（成功/失败、不同攻击）在最后 token 上的激活。
  - 投影至 `w_toxic`，统计均值与方差。
- **功能象限**：
  - S+A+, S−A+, S+A−, S−A− 四类分区，输出给前端。
- **梯度关联 \(G_{i,j}\)**：
  - 对安全神经元进行反向传播，计算上游节点对其激活的梯度贡献。
  - 选取 Top-k（如 10%）建立连接图，存储为稀疏矩阵或 edge list。
- **神经元干预**：
  - 开发“断开神经元”接口：将指定神经元输出置零，重新前向，观测表征与输出变化。
  - 提供缓存机制，避免频繁重复前向。

### 3.5 模块五：定向安全微调（R6）
- **数据构造**：
  - 针对成功越狱案例生成拒答模板：采集常见安全拒绝语句 + SALAD-Bench 分类标签组合。
  - 保证不同模板随机组合，避免模型过拟合固定模式。
- **微调策略**：
  - 实现 TSFT（只更新安全神经元）与论文提出的 VA+TSFT（额外调整脆弱神经元）。
  - 训练参数：学习率、梯度裁剪、epoch（论文示例 1 epoch）。
  - 记录训练损失、验证 ASR。
- **对照实验**：
  - 同一数据集上运行全量微调、LoRA、TSFT、VA+TSFT，保持 epoch 与 batch size 一致。
  - 输出对比表格、损失曲线（复现表 1、图 8）。

---

## 阶段 4：可视化界面实现

### 4.1 后端服务
- 提供统一 API（REST/WebSocket）：
  - `/metrics`：返回评估指标
  - `/representation`：返回指定层的散点/流图数据
  - `/neurons`：返回神经元功能、连接、激活统计
  - `/intervene`：执行神经元禁用并返回影响结果
  - `/fine_tune`：触发微调任务 / 返回微调日志
- 实现缓存层（Redis/SQLite）以加速常用查询。

### 4.2 前端视图（对应论文 Fig.1）
- **控制面板**：模型/攻击选择、参数配置、微调操作。
- **指标视图**：雷达图 + 时间序列展示微调前后指标对比。
- **表征视图**：PCA 散点 + 决策边界投影（可切换模式），支持样本高亮。
- **层视图**：流图（展示成功/失败样本比例变动）+ 梯度连线，可刷选样本集合。
- **神经元视图**：多层径向布局：
  - 外圈：W_down 神经元，按功能象限着色。
  - 曲线：对齐度、激活强度、相似度。
  - 内圈：上游神经元，力导布局展示连接。
  - 交互：鼠标悬停显示属性，点击触发断开/标记。
- **实例视图**：显示 prompt、模型回复、分类器评估，支持“星标”与集合保存。

### 4.3 交互联动
- 样本 ID、层号、神经元索引统一主键，支持跨视图高亮与过滤。
- 神经元禁用后的结果实时推送到表征视图和指标视图。
- 提供版本对比模式（原始模型 vs 微调模型）并行展示。

### 4.4 前端测试
- 单测：组件渲染、数据解析、交互逻辑。
- E2E 测试：使用 Cypress/Playwright 自动化操作常见分析流程。

---

## 阶段 5：实验复现

### 5.1 案例研究（Section 7.1）
- **Case I**：逐层探索 AutoDan 防御机制。
  - 记录操作序列：指标评估 → 表征/层视图分析 → 神经元功能定位 → 断开实验。
  - 生成截图：流图、神经元视图、断开前后散点变化。
- **Case II**：安全漏洞定位与强化。
  - 重现从末层回溯 → 子集对比 → 梯度连接分析 → 微调强化的流程。
  - 保存关键步骤截图与文字描述。
- **文档化**：以实验日志形式记录每一步输入、观察与结论。

### 5.2 专家访谈（Section 7.2）
- 若条件允许，邀请至少 1 名安全研究者试用。
- 准备访谈提纲：可视化易用性、解释方法有效性、改进建议。
- 输出访谈纪要；若无法实施，撰写自评与潜在用户反馈假设。

### 5.3 定量实验（Section 7.3）
- **指标复现**：
  - 按表 1 格式输出各方法 ASR 与效用。
  - 生成损失曲线（图 8），并与论文趋势对比。
- **差异分析**：
  - 如结果与论文存在偏差，分析可能原因（模型版本、硬件、数据差异）。
  - 记录所有实验配置，确保可重复。

---

## 阶段 6：文档与开源

- **使用指南**：包含环境安装、数据准备、脚本运行、界面启动步骤。
- **复现报告**：详细描述实现过程、问题与解决方案、结果对比、未来优化。
- **演示资料**：
  - 录制可视化操作视频。
  - 导出关键图表（雷达图、流图、神经元视图、损失曲线）。
- **代码整理**：
  - 清理调试脚本、补充注释。
  - 编写 `makefile` / `invoke` 命令，支持一键运行关键流程。
- **开源准备**：
  - 评估共享模型/数据合规性。
  - 编写贡献指南与 issue 模板。

---

## 风险与应对

- **硬件压力**：层级隐藏态与梯度存储量大 → 采用分块存储、按需加载；必要时使用更小模型验证。
- **模型不可得**：若 meta-llama/Llama-3.2-3B 或 Llama-Guard-3-1B 权限受限，需选择替代模型并在报告中说明差异。
- **探针精度不足**：尝试特征标准化、增加样本或采用非线性探针（如 MLP、核方法）验证对结果的影响。
- **前端性能瓶颈**：对大规模数据实施抽样与分层加载；提供后端聚合接口。
- **时间控制**：关键路径设立里程碑评审，避免后期返工；并行推进各模块。

---

## 验证清单

- [ ] SALAD-Bench 全部攻击样本成功加载并完成基线评测。
- [ ] 各层探针训练完成，精度达到论文描述水平，并生成毒性向量。
- [ ] 安全神经元定位与分类结果可视化，支持禁用操作。
- [ ] 可视化界面复现论文六个视图的核心交互。
- [ ] TSFT 与 VA+TSFT 微调策略实现，输出对照实验结果。
- [ ] 案例研究流程复现并形成文字+截图记录。
- [ ] 复现报告与开源使用指南交付。

---

## 后续扩展方向

- **攻击多样性**：引入最新越狱策略（如语义改写、多轮对话）验证系统适应性。
- **非线性解释**：探索高阶探针、概念激活向量等方法增强解释精度。
- **自动化红队**：结合强化学习或 agent-based 生成器，实现在线红队与防御闭环。
- **跨模型比较**：扩展到不同体系结构（Mistral、Qwen）并比较安全机制差异。
- **用户支持工具**：开发脚本自动生成分析报告，降低专家使用门槛。

---

> 若需进一步细化某个模块（如 SNIP 实现细节、前端组件拆分、自动化测试流程等），请在下一步明确需求。


